{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import pinecone\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.llms import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the document\n",
    "\n",
    "def readDoc(directory):\n",
    "    file_loader = PyPDFDirectoryLoader(directory)\n",
    "    docs = file_loader.load()\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1259"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = readDoc('docs/')\n",
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide docs into chunks\n",
    "\n",
    "def chunkData(docs,chunk_size=500,chunk_overlap=50):\n",
    "    text_spiltter = RecursiveCharacterTextSplitter(chunk_size=chunk_size,chunk_overlap=chunk_overlap)\n",
    "    doc = text_spiltter.split_documents(docs)\n",
    "\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1259"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = chunkData(docs=doc)\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Applications\\myenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-mpnet-base-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embedding technique of Hugging face\n",
    "embedding = HuggingFaceEmbeddings()\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = embedding.embed_query(\"How are you buddy?\")\n",
    "len(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone.control.pinecone.Pinecone at 0x2e8310bd340>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search in Vector DB -pinecone\n",
    "from pinecone import Pinecone\n",
    "pc = Pinecone(api_key=\"7625c1cf-dee4-4560-a4b2-71413b619cbb\")\n",
    "pc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "os.environ['PINECONE_API_KEY'] = \"7625c1cf-dee4-4560-a4b2-71413b619cbb\"\n",
    "index = PineconeVectorStore.from_documents(doc,index_name=\"quiz-app\",embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrive result\n",
    "\n",
    "def retrivequery(query,k=2):\n",
    "    matching = index.similarity_search(query=query,k=k)\n",
    "    return matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n",
      "WARNING! token is not default parameter.\n",
      "                    token was transferred to model_kwargs.\n",
      "                    Please make sure that token is what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to C:\\Users\\Dipam1\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n",
    "\n",
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "llm_hug = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id, max_length=128, temperature=0.9, token=\"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\"\n",
    ")\n",
    "\n",
    "chain = load_qa_chain(llm_hug,chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search answers from Vector DB\n",
    "\n",
    "def retriveAnswer(query):\n",
    "    doc_search = retrivequery(query)\n",
    "    response = chain.run(input_documents = doc_search,question = query)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I cannot create MCQ questions based on the context provided because it discusses the reasons why Python is popular and the style and structure of this book. Here are five multiple-choice questions on Python language fundamentals that might help you get started:\n",
      "1. What is the default data type for a variable that has not been initialized in Python?\n",
      "   a) Integer\n",
      "   b) String\n",
      "   c) List\n",
      "   d) None\n",
      "   Answer: d) None\n",
      "2. What is the name of Pythonâ€™s looping construct that lets you repeat a block of code a specific number of times?\n",
      "   a) for loop\n",
      "   b) while loop\n",
      "   c) if loop\n",
      "   d) try loop\n",
      "   Answer: a) for loop\n",
      "3. Which Python keyword is used to define a function?\n",
      "   a) if\n",
      "   b) for\n",
      "   c) def\n",
      "   d) try\n",
      "   Answer: c) def\n",
      "4. What does the print() function do in Python?\n",
      "   a) It assigns a value to a variable.\n",
      "   b) It executes a loop.\n",
      "   c) It displays output to the screen.\n",
      "   d) It performs a mathematical operation.\n",
      "   Answer: c) It displays output to the screen.\n",
      "5. In Python, what is the difference between a list and a tuple?\n",
      "   a) Lists are mutable, while tuples are immutable.\n",
      "   b) Lists are used for string operations, while tuples are used for list operations.\n",
      "   c) Lists are faster than tuples.\n",
      "   d) There is no difference.\n",
      "   Answer: a) Lists are mutable, while tuples are immutable.\n"
     ]
    }
   ],
   "source": [
    "question = \"Give me 5 MCQ questions on python programming language?\"\n",
    "answer = retriveAnswer(question)\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
